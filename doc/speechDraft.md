8.一路向北背景


虚商是一个偏横向的项目，我在项目过程中积累了很多横向项目的经验，再加上我是交易老人，对交易的全链路都比较了解，所以就有幸作为交易的接口人，参与了一路向北的这个项目中。 

一路向北，简单来说就是上海机房裁撤，需要将相关的应用和数据库从上海搬迁到张北。由于我们交易主要涉及的是预付费的核心链路，对业务的影响容忍度比较低，就更加需要 一套比较完善的迁移方案。

当然，对于我来说，对于一路向北的理解，它不仅仅是一个搬迁，还是一个底层架构的升级，一个技术练兵的机会。

我们可以利用这个机会，改掉一些不合理的地方（数据拆分），提升稳定性（数据扩容）。

另外，我们终于可以跟用户一样，使用我们自己的云产品，吃自己的狗粮，改善和优化它们。(比如 rds控制台的创建只读实例的功能，这是我刚进交易组做的功能，如今可以在这个项目中使用到，能亲身体会到我们凌霄的能力，很有成就感)


9.面临挑战
当然对于整个迁移来说，我们会面临几方面的挑战：

一.应用层面： 

由于迁移张北会带来时延问题， 那些核心链路上的、有相互依赖、对时延敏感的应用 ，我们叫做核心应用，这些应用需要再统一的窗口一并迁移，比如下单、支付；

那些不敏感的应用可以提前迁移，比如小二后台。

还有一些核心链路上的基础服务，比如账号，它不迁移，但会配合我们在张北部署只读服务；

我需要评估好这些上下游依赖，区分好应用级别，制定相应的迁移策略。

二.数据库层面：

1.统一的策略是DNS切库，大部分都是这样

2.部分需要拆分和扩容的数据库，比如说我们订单库，则需要通过代码发布的方式切流。

3.还有一些库，相关依赖的应用不迁移，我们必须制定特殊的策略，来处理这类数据库。

三.项目管理上面：

时间紧，迁移应用多，迁移方案不统一； 疫情原因，沟通也不顺畅； 另外因为是横向项目，推动相关同学还是会遇到一些困难。


10.我的计划
针对这些挑战，我做了以下计划：

我将整个迁移 ，分成了以下几个阶段：

1.准备阶段。主要是整理迁移信息，选定一个非核心应用，预发部署。

2.摸底阶段。这个阶段主要是将之前选定的应用，发布上线，在这个过程中，收集遇到的问题，及时发现风险，整理成文档，进行经验分享。另外，根据自己理解，以及跟各

个域同学确认，哪些是核心应用，哪些是非核心应用，确认最终的迁移节奏。

3.攻坚阶段。这个阶段是最忙碌最重要的时候，一方面 要推动 团队 同学按照迁移计划，制定方案，进行非核心应用的迁移，保证迁移的稳定性。 另一方面 

要进行核心链路的预发测试，根据最终的发布策略，制定迁移方案，并反复进行评审。

4.最后迁移阶段。 根据之前发现的风险点，进行演练，降低风险，以及最后的迁移工作。

总结起来，一共是两方面的工作，技术管理上 主要是应用和数据库方案的制定，以及核心链路的测试，项目管理上，一个是经验分享，一个是推动团队按计划执行迁移。


11.预发测试

整个迁移中，最重要最关键的的就是最终的迁移策略，而这个需要通过预发的测试才能确定。

左边这些是我们核心链路上的各个应用，左边的是基础服务，右边的是业务系统，核心链路下单支付的时候 ，是走的右边的业务系统，但是依赖的商品账号等能力又是 

这些基础服务提供的。  预发测试的过程，就是张北的这些应用，连接上海的数据库，在张北的环境里进行全链路测试。

起初我们也是想通过灰度发布的方式，将所有应用系统都在张北发上线，通过流量隔离的方式，不提供服务。 

再通过灰度的方式逐步切流，验证问题，发现风险。最后再统一切库切流，数据库和流量一并切到张北。

优点是显而易见的：应用发布的风险几乎没有（因为有充分的时间线上验证），最终的方案足够简单(就是数据库切库和切流)。

这个策略我们需要解决两个问题：

一个是应用间的调用延迟，这个集团有统一的策略，HSF的同机房优先原则。当时我负责的commonDriver有用类似的hsf路由规则来做灰度发布，所以最终就由我去做了相

关规则的探究；确认规则前提以后，我先在交易的小团队里进行了链路测试，结果符合预期；再推广到全链路，我组织全链路上下游的各个同学，一起开启相关路由规则，进

行测试，最终得出了一份测试报告:结果符合预期。 


再一个是数据库的延迟，这个其实是开启同机房优先以后，钉钉预发测试发现的，他们只部署在张北机房，最终确认原因是数据库的延迟导致，看似30ms,但是代码里如果不

是足够规范，会有好多个30ms出现。 这个场景其实当时我们是通过代码优化，提高了一倍的效率的。 

但是最终的预发测试效果不够理想，数据库的延迟通过我们的代码放大了影响，我们最终没有采用这样的灰度策略。

当然我们还是遵循 能做的事情尽量提前做，最后一晚的操作尽量简单的原则 来确认发布策略的，简单说下：

1.确保 张北的代码配置项和 上海是隔离的。

2.通过aone waitonline方式提前 把代码发到张北机器上。

3.数据库禁写切库时，重启张北应用，下线上海应用，进行流量切换。


12.对比集团
经历了一路向北迁移，我再思考，我们如何能让类似的迁移，变得更加的稳定，靠谱，和润滑。
然后我去查了下资料，了解了下 集团他们的最终迁移方案，我理解的最核心的点:

他们使用了灰度发布的方式，将所有涉及的应用提前发布上了线。

这里面有几个关键点:

1.集团提前做了底层部署架构的统一，都是pouch化部署，前期的机器申请和部署，他们通过平台工具都可以完成，无需人工干预

2.需要克服数据库的延迟。这个也是我们遇到的问题，由于我们的预发测试效果不理想，最终没有采用。 对于淘系来说，他们提前进行了相关的场景优化，以及做了风险预案，容忍了这个场景。

3.流量隔离能力。 充分利用了中间件的力量，实现了metaq的机房隔离，以及configserver的单向可见(上海看不到张北，张北可以看到上海)

4.精确切流，利用dns/vipserver的能力，直接将%1的流量引到张北，回滚也很方便。

而我们运营支撑平台，底层部署没有容器化(webx,pandoraboot)，还有一些少量的dubbo调用，这是其一；我们的数据库切换方案不统一，即使我们使用了灰度上线的方式，最终那天晚上，我们一些应用仍然需要通过代码发布的方式切换数据库路由,这是其二;最后，我们有很多场景还是有效率优化的空间，因此，这个数据库的延迟，放大了这些代码的效率问题，再加上时间比较紧，所以最终没有采用灰度方案的方式。

但是我们依赖aone的wait_online的机制，以及提前的演练，也大大缩短了最后的发布时间，降低了风险。
